{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdAQ4HGjNdi8"
      },
      "source": [
        "# HW#8\n",
        "> 2022094093 Kim Dohoon, Dept of Data Science\n",
        "- 3-layer-MLP\n",
        "- Dense - Dense - Dense\n",
        "    - Nadam Optimizer, batch_size = 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modules\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import random as rn\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pylab as plt\n",
        "import os\n",
        "\n",
        "path = '/Users/tt/Documents/Programming Files/Data_Science_Fundementals/Codes/experiment'\n",
        "scce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    reduction = tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
        ")\n",
        "\n",
        "###### Do not modify ######\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "rn.seed(1)\n",
        "###########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial Setting\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "train_images = train_images.reshape(60000, -1).astype(np.float32)\n",
        "test_images = test_images.reshape(10000, -1).astype(np.float32)\n",
        "train_images, test_images = train_images/255.0, test_images/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dropout_graph(i, history, opt, bs, drop):\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('Accuracy')\n",
        "    plt.plot(history.history[\"accuracy\"], 'b', label='Train')\n",
        "    plt.plot(history.history['val_accuracy'],'r', label='Test')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('Loss')\n",
        "    plt.plot(history.history[\"loss\"], 'b', label='Train')\n",
        "    plt.plot(history.history['val_loss'],'r', label='Test')\n",
        "    plt.legend()\n",
        "    title = f\"{i}_model_{opt}_{bs}_{drop}\"\n",
        "    plt.savefig(f\"{path}/Dropout/{title}.jpg\")\n",
        "    plt.cla()\n",
        "\n",
        "def non_dropout_graph(i, history, opt, bs):\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('Accuracy')\n",
        "    plt.plot(history.history[\"accuracy\"], 'b', label='Train')\n",
        "    plt.plot(history.history['val_accuracy'],'r', label='Test')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('Loss')\n",
        "    plt.plot(history.history[\"loss\"], 'b', label='Train')\n",
        "    plt.plot(history.history['val_loss'],'r', label='Test')\n",
        "    plt.legend()\n",
        "    title = f\"{i}_model_{opt}_{bs}\"\n",
        "    plt.savefig(f\"{path}/NonDropout/{title}.jpg\")\n",
        "    plt.cla()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Non Dropout\n",
        "\n",
        "def non_dropout_model(opt, bs):\n",
        "    model = Sequential()\n",
        "    num_pixels = train_images.shape[1]\n",
        "\n",
        "    model.add(layers.Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss=scce,\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(\n",
        "        train_images, train_labels,\n",
        "        epochs=30,\n",
        "        batch_size=bs,\n",
        "        validation_data = (test_images, test_labels)\n",
        "    )\n",
        "    val_loss, val_accuracy = model.evaluate(test_images, test_labels, verbose=2)\n",
        "    non_dropout_graph(j, hist, opt, bs)\n",
        "    return val_loss, val_accuracy\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dropout\n",
        "\n",
        "def dropout_model(opt, bs, drop):\n",
        "    model = Sequential()\n",
        "    num_pixels = train_images.shape[1]\n",
        "\n",
        "    model.add(layers.Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
        "    model.add(layers.Dropout(drop))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss=scce,\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(\n",
        "        train_images, train_labels,\n",
        "        epochs=30,\n",
        "        batch_size=bs,\n",
        "        validation_data = (test_images, test_labels)\n",
        "    )\n",
        "    val_loss, val_accuracy = model.evaluate(test_images, test_labels, verbose=2)\n",
        "    dropout_graph(j, hist, opt, bs, drop)\n",
        "    return val_loss, val_accuracy\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt_list = ['nadam', 'adam', 'sgd']\n",
        "bs_list = [16, 32, 64, 128, 10000, 60000]\n",
        "dropout_list = [0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'opt_list' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/tt/Documents/Programming Files/Data_Science_Fundementals/Codes/HW_8_Dense.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/Codes/HW_8_Dense.ipynb#ch0000007?line=3'>4</a>\u001b[0m d_loss_sum \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/Codes/HW_8_Dense.ipynb#ch0000007?line=4'>5</a>\u001b[0m j \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/Codes/HW_8_Dense.ipynb#ch0000007?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m opt \u001b[39min\u001b[39;00m opt_list:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/Codes/HW_8_Dense.ipynb#ch0000007?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m bs \u001b[39min\u001b[39;00m bs_list:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/Codes/HW_8_Dense.ipynb#ch0000007?line=7'>8</a>\u001b[0m         \u001b[39mfor\u001b[39;00m dropout \u001b[39min\u001b[39;00m dropout_list:\n",
            "\u001b[0;31mNameError\u001b[0m: name 'opt_list' is not defined"
          ]
        }
      ],
      "source": [
        "nd_acc_sum = []\n",
        "nd_loss_sum = []\n",
        "d_acc_sum = []\n",
        "d_loss_sum = []\n",
        "j = 1\n",
        "for opt in opt_list:\n",
        "    for bs in bs_list:\n",
        "        for dropout in dropout_list:\n",
        "            nd_loss, nd_accuracy = non_dropout_model(opt, bs)\n",
        "            nd_acc_sum.append(nd_accuracy)\n",
        "            nd_loss_sum.append(nd_loss)\n",
        "\n",
        "            d_loss, d_accuracy = dropout_model(opt, bs, dropout)\n",
        "            d_acc_sum.append(d_accuracy)\n",
        "            d_loss_sum.append(d_loss)\n",
        "            j += 1\n",
        "\n",
        "nd_best = max(nd_acc_sum)\n",
        "d_best = max(d_acc_sum)\n",
        "print(f'''\n",
        "Best accuracy in Non-Dropout model : {nd_best} at index {nd_acc_sum.index(nd_best)}\n",
        "\n",
        "Best accuracy in Dropout model : {d_best} at index {d_acc_sum.index(d_best)}\n",
        "''')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-01 15:35:10.838085: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 892ms/step - loss: 2.3602 - accuracy: 0.1359 - val_loss: 1.8111 - val_accuracy: 0.3515\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 1.8085 - accuracy: 0.3530 - val_loss: 1.5587 - val_accuracy: 0.5676\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 1.5547 - accuracy: 0.5764 - val_loss: 1.3591 - val_accuracy: 0.6350\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 1.3529 - accuracy: 0.6414 - val_loss: 1.1762 - val_accuracy: 0.6226\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 1s 503ms/step - loss: 1.1694 - accuracy: 0.6292 - val_loss: 1.1438 - val_accuracy: 0.6269\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 1.1335 - accuracy: 0.6328 - val_loss: 1.1414 - val_accuracy: 0.6228\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 1.1348 - accuracy: 0.6297 - val_loss: 1.0660 - val_accuracy: 0.6635\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 1.0497 - accuracy: 0.6681 - val_loss: 1.0210 - val_accuracy: 0.6653\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 1.0118 - accuracy: 0.6679 - val_loss: 0.9604 - val_accuracy: 0.7029\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.9433 - accuracy: 0.7130 - val_loss: 0.8928 - val_accuracy: 0.7081\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.8803 - accuracy: 0.7161 - val_loss: 0.8500 - val_accuracy: 0.7059\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.8320 - accuracy: 0.7183 - val_loss: 0.8703 - val_accuracy: 0.7240\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.8557 - accuracy: 0.7328 - val_loss: 0.7666 - val_accuracy: 0.7351\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.7491 - accuracy: 0.7528 - val_loss: 0.7999 - val_accuracy: 0.7273\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.7846 - accuracy: 0.7386 - val_loss: 0.7976 - val_accuracy: 0.7278\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.7773 - accuracy: 0.7422 - val_loss: 0.8593 - val_accuracy: 0.7099\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.8434 - accuracy: 0.7161 - val_loss: 0.8339 - val_accuracy: 0.7108\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.8132 - accuracy: 0.7207 - val_loss: 0.7729 - val_accuracy: 0.7245\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 1s 516ms/step - loss: 0.7540 - accuracy: 0.7328 - val_loss: 0.7183 - val_accuracy: 0.7478\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 1s 518ms/step - loss: 0.6977 - accuracy: 0.7582 - val_loss: 0.6987 - val_accuracy: 0.7504\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.6783 - accuracy: 0.7584 - val_loss: 0.6759 - val_accuracy: 0.7576\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 1s 508ms/step - loss: 0.6553 - accuracy: 0.7707 - val_loss: 0.6747 - val_accuracy: 0.7566\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.6526 - accuracy: 0.7682 - val_loss: 0.6653 - val_accuracy: 0.7561\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 1s 516ms/step - loss: 0.6448 - accuracy: 0.7700 - val_loss: 0.6847 - val_accuracy: 0.7504\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 1s 521ms/step - loss: 0.6595 - accuracy: 0.7626 - val_loss: 0.6817 - val_accuracy: 0.7621\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6620 - accuracy: 0.7727 - val_loss: 0.6591 - val_accuracy: 0.7559\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 1s 508ms/step - loss: 0.6331 - accuracy: 0.7723 - val_loss: 0.6782 - val_accuracy: 0.7680\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.6588 - accuracy: 0.7782 - val_loss: 0.6336 - val_accuracy: 0.7721\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 1s 507ms/step - loss: 0.6079 - accuracy: 0.7903 - val_loss: 0.6804 - val_accuracy: 0.7642\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6605 - accuracy: 0.7724 - val_loss: 0.6517 - val_accuracy: 0.7754\n",
            "313/313 - 0s - loss: 0.6517 - accuracy: 0.7754 - 232ms/epoch - 742us/step\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "num_pixels = train_images.shape[1]\n",
        "\n",
        "model.add(layers.Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.compile(\n",
        "    optimizer='nadam',\n",
        "    loss=scce,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=30,\n",
        "    batch_size=1000,\n",
        "    validation_data = (test_images, test_labels)\n",
        ")\n",
        "val_loss, val_accuracy = model.evaluate(test_images, test_labels, verbose=2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "HW#8_Code.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "6a2ab8426269d42ee9fba94d9eb5b0a8b7f95b47bc074ef128370580d7ae2931"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('ds')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
