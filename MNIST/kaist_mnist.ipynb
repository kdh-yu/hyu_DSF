{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "\n",
    "def cnn_fn(features, labels, mode):\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])  # You also can use 1 x 784 vector\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.keras.layers.Conv2D(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.keras.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.keras.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu,\n",
    "    )\n",
    "    pool2 = tf.keras.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #3 and Pooling Layer #3\n",
    "    conv3 = tf.keras.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu,\n",
    "    )\n",
    "    pool3 = tf.keras.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=1)\n",
    "\n",
    "    # Convolutional Layer #4 and Pooling Layer #4\n",
    "    conv4 = tf.keras.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu,\n",
    "    )\n",
    "    pool4 = tf.keras.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=1)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool4_flat = tf.reshape(pool4, [-1, 5 * 5 * 64])\n",
    "    dense = tf.keraslayers.dense(inputs=pool4_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.keras.layers.dropout(\n",
    "        inputs=dense, rate=0.25, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Output logits Layer\n",
    "    logits = tf.keras.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    # In predictions, return the prediction value, do not modify\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Select your loss and optimizer from tensorflow API\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)  # Refer to tf.losses\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)  # Refer to tf.train\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.layers' has no attribute 'Convolution2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/tt/Documents/Programming Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000002?line=26'>27</a>\u001b[0m train_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mnumpy_input_fn(x\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: train_data},\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000002?line=27'>28</a>\u001b[0m                                                     y\u001b[39m=\u001b[39mtrain_labels, batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, num_epochs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000002?line=28'>29</a>\u001b[0m \u001b[39m#train_input = tf.estimator.inputs.numpy_input_fn(x={\"x\": train_data},\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000002?line=29'>30</a>\u001b[0m \u001b[39m#                                                    y=train_labels, batch_size=100, num_epochs=None, shuffle=True)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000002?line=30'>31</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mtrain(input_fn\u001b[39m=\u001b[39;49mtrain_input, steps\u001b[39m=\u001b[39;49m\u001b[39m20000\u001b[39;49m, hooks\u001b[39m=\u001b[39;49m[logging_hook])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000002?line=32'>33</a>\u001b[0m \u001b[39m# Eval the model. You can evaluate your trained model with validation data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000002?line=33'>34</a>\u001b[0m eval_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mnumpy_input_fn(x\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: eval_data},\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000002?line=34'>35</a>\u001b[0m                                                 y\u001b[39m=\u001b[39meval_labels, num_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=356'>357</a>\u001b[0m hooks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[1;32m    <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=358'>359</a>\u001b[0m saving_listeners \u001b[39m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[0;32m--> <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=359'>360</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model(input_fn, hooks, saving_listeners)\n\u001b[1;32m    <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=360'>361</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mLoss for final step: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[1;32m    <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=361'>362</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py:1186\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1183'>1184</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1184'>1185</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1185'>1186</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model_default(input_fn, hooks, saving_listeners)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py:1214\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1210'>1211</a>\u001b[0m features, labels, input_hooks \u001b[39m=\u001b[39m (\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1211'>1212</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_features_and_labels_from_input_fn(input_fn, ModeKeys\u001b[39m.\u001b[39mTRAIN))\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1212'>1213</a>\u001b[0m worker_hooks\u001b[39m.\u001b[39mextend(input_hooks)\n\u001b[0;32m-> <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1213'>1214</a>\u001b[0m estimator_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_model_fn(features, labels, ModeKeys\u001b[39m.\u001b[39;49mTRAIN,\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1214'>1215</a>\u001b[0m                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig)\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1215'>1216</a>\u001b[0m global_step_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mget_global_step(g)\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1216'>1217</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1217'>1218</a>\u001b[0m                                        hooks, global_step_tensor,\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1218'>1219</a>\u001b[0m                                        saving_listeners)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py:1174\u001b[0m, in \u001b[0;36mEstimator._call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1170'>1171</a>\u001b[0m   kwargs[\u001b[39m'\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m config\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1172'>1173</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mCalling model_fn.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1173'>1174</a>\u001b[0m model_fn_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_fn(features\u001b[39m=\u001b[39;49mfeatures, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1174'>1175</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mDone calling model_fn.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   <a href='file:///Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py?line=1176'>1177</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model_fn_results, model_fn_lib\u001b[39m.\u001b[39mEstimatorSpec):\n",
      "\u001b[1;32m/Users/tt/Documents/Programming Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb Cell 2'\u001b[0m in \u001b[0;36mcnn_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=4'>5</a>\u001b[0m input_layer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(features[\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m1\u001b[39m])  \u001b[39m# You also can use 1 x 784 vector\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=6'>7</a>\u001b[0m \u001b[39m# Convolutional Layer #1\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=7'>8</a>\u001b[0m conv1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConvolution2d(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=8'>9</a>\u001b[0m     inputs\u001b[39m=\u001b[39minput_layer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=9'>10</a>\u001b[0m     filters\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=10'>11</a>\u001b[0m     kernel_size\u001b[39m=\u001b[39m[\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=11'>12</a>\u001b[0m     padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=12'>13</a>\u001b[0m     activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=15'>16</a>\u001b[0m \u001b[39m# Pooling Layer #1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tt/Documents/Programming%20Files/Data_Science_Fundementals/MNIST/kaist_mnist.ipynb#ch0000001?line=16'>17</a>\u001b[0m pool1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mmax_pooling2d(inputs\u001b[39m=\u001b[39mconv1, pool_size\u001b[39m=\u001b[39m[\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m], strides\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.layers' has no attribute 'Convolution2d'"
     ]
    }
   ],
   "source": [
    "# Write your dataset path\n",
    "#dataset_train = np.load('/content/gdrive/My Drive/mnist-cnn-test/train.npy')\n",
    "#dataset_eval = np.load('/content/gdrive/My Drive/mnist-cnn-test/valid.npy')\n",
    "#test_data = np.load('/content/gdrive/My Drive/mnist-cnn-test/test.npy')\n",
    "\n",
    "#dataset_train = np.load('./train.npy')\n",
    "#dataset_eval = np.load('./valid.npy')\n",
    "#test_data = np.load('./test.npy')\n",
    "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
    "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
    "\n",
    "with np.load(path) as data:\n",
    "    train_data = data['x_train']#dataset_train[:, :784]\n",
    "    train_labels = data['y_train']#dataset_train[:, 784].astype(np.int32)\n",
    "    eval_data = data['x_test']#[:, :784]\n",
    "    eval_labels = data['y_test']#dataset_eval[:, 784].astype(np.int32)\n",
    "\n",
    "# Save model and checkpoint\n",
    "classifier = tf.estimator.Estimator(model_fn=cnn_fn, model_dir=\"./model\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.estimator.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "#logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "# Train the model. You can train your model with specific batch size and epoches\n",
    "train_input = tf.compat.v1.estimator.inputs.numpy_input_fn(x={\"x\": train_data},\n",
    "                                                    y=train_labels, batch_size=100, num_epochs=None, shuffle=True)\n",
    "#train_input = tf.estimator.inputs.numpy_input_fn(x={\"x\": train_data},\n",
    "#                                                    y=train_labels, batch_size=100, num_epochs=None, shuffle=True)\n",
    "classifier.train(input_fn=train_input, steps=20000, hooks=[logging_hook])\n",
    "\n",
    "# Eval the model. You can evaluate your trained model with validation data\n",
    "eval_input = tf.estimator.inputs.numpy_input_fn(x={\"x\": eval_data},\n",
    "                                                y=eval_labels, num_epochs=1, shuffle=False)\n",
    "eval_results = classifier.evaluate(input_fn=eval_input)\n",
    "\n",
    "## ----------- Do not modify!!! ------------ ##\n",
    "# Predict the test dataset\n",
    "pred_input = tf.estimator.inputs.numpy_input_fn(x={\"x\": test_data}, shuffle=False)\n",
    "pred_results = classifier.predict(input_fn=pred_input)\n",
    "result = np.asarray([x.values()[1] for x in list(pred_results)])\n",
    "## ----------------------------------------- ##\n",
    "\n",
    "# np.save('./result.npy', result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a2ab8426269d42ee9fba94d9eb5b0a8b7f95b47bc074ef128370580d7ae2931"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
